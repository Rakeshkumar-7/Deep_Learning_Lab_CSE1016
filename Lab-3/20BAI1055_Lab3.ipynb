{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22b1bab0",
   "metadata": {},
   "source": [
    "# Name: Rakesh Kumar K S\n",
    "# Reg. no: 20BAI1055\n",
    "## DL Lab 3 - CNN Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ff3fe9",
   "metadata": {},
   "source": [
    "## Dataset 1 - MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8515dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad481cb",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b63fb0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65a8aa1",
   "metadata": {},
   "source": [
    "### Flattening the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ca3415b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6019cd74",
   "metadata": {},
   "source": [
    "### Normalizing the pixel values between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e0b4d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09df72c9",
   "metadata": {},
   "source": [
    "### Number of output classes(0 to 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d56b234",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b15416c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (60000,)\n",
      "Shape after one-hot encoding:  (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
    "Y_train = np_utils.to_categorical(y_train, n)\n",
    "Y_test = np_utils.to_categorical(y_test, n)\n",
    "print(\"Shape after one-hot encoding: \", Y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04171424",
   "metadata": {},
   "source": [
    "### Creating the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc5875eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bc08f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a Dense layer\n",
    "model.add(Dense(100, input_shape=(28*28,), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa8cf078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding output Dense layer. Since we have 10 categories, we'll have 10 neurons at the output layer\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0c74d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarizing the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54263d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c3d5784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3896 - accuracy: 0.8930 - val_loss: 0.2154 - val_accuracy: 0.9388\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.1842 - accuracy: 0.9480 - val_loss: 0.1494 - val_accuracy: 0.9558\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.1336 - accuracy: 0.9620 - val_loss: 0.1211 - val_accuracy: 0.9637\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.1040 - accuracy: 0.9707 - val_loss: 0.1058 - val_accuracy: 0.9677\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0860 - accuracy: 0.9759 - val_loss: 0.0904 - val_accuracy: 0.9723\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0727 - accuracy: 0.9792 - val_loss: 0.0931 - val_accuracy: 0.9717\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0616 - accuracy: 0.9821 - val_loss: 0.0832 - val_accuracy: 0.9740\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0532 - accuracy: 0.9844 - val_loss: 0.0777 - val_accuracy: 0.9742\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0454 - accuracy: 0.9867 - val_loss: 0.0775 - val_accuracy: 0.9757\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0402 - accuracy: 0.9886 - val_loss: 0.0762 - val_accuracy: 0.9766\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0345 - accuracy: 0.9902 - val_loss: 0.0769 - val_accuracy: 0.9766\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0297 - accuracy: 0.9920 - val_loss: 0.0751 - val_accuracy: 0.9763\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0257 - accuracy: 0.9933 - val_loss: 0.0730 - val_accuracy: 0.9759\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0235 - accuracy: 0.9944 - val_loss: 0.0707 - val_accuracy: 0.9786\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0204 - accuracy: 0.9949 - val_loss: 0.0739 - val_accuracy: 0.9776\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0173 - accuracy: 0.9959 - val_loss: 0.0735 - val_accuracy: 0.9784\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0157 - accuracy: 0.9962 - val_loss: 0.0801 - val_accuracy: 0.9767\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0131 - accuracy: 0.9970 - val_loss: 0.0791 - val_accuracy: 0.9780\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0115 - accuracy: 0.9978 - val_loss: 0.0762 - val_accuracy: 0.9778\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0099 - accuracy: 0.9979 - val_loss: 0.0871 - val_accuracy: 0.9772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x217e4bf6df0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=128, epochs=20, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbb94b4",
   "metadata": {},
   "source": [
    "## Dataset 2 - CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61dda14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c283e3",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca3aba34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 15s 0us/step\n",
      "170508288/170498071 [==============================] - 15s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0673327a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 32, 32, 3)\n",
    "X_test = X_test.reshape(X_test.shape[0], 32, 32, 3)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a53e28e",
   "metadata": {},
   "source": [
    "### Normzaling the RGB pixel values between 0 and 1 (min value of a pixel is 0 and max is 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77f4cb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2082d2b",
   "metadata": {},
   "source": [
    "### Number of output classes(0 to 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37c285f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84459f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (50000, 1)\n",
      "Shape after one-hot encoding:  (50000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
    "Y_train = np_utils.to_categorical(y_train, n)\n",
    "Y_test = np_utils.to_categorical(y_test, n)\n",
    "print(\"Shape after one-hot encoding: \", Y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294aef84",
   "metadata": {},
   "source": [
    "### Building the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68420356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "428dd0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "010043d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(50, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(Conv2D(75, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(125, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "091145a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78bbdd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# output layer\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14240fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d7d26d",
   "metadata": {},
   "source": [
    "### Creating a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "415e6bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d472a421",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0c115e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 32, 32, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98121dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b6296d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 [==============================] - 251s 796ms/step - loss: 1.7292 - accuracy: 0.3583 - val_loss: 1.3288 - val_accuracy: 0.5269\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - 252s 803ms/step - loss: 1.2466 - accuracy: 0.5538 - val_loss: 1.0526 - val_accuracy: 0.6290\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 390s 1s/step - loss: 1.0182 - accuracy: 0.6403 - val_loss: 0.8915 - val_accuracy: 0.6884\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - 473s 2s/step - loss: 0.8950 - accuracy: 0.6877 - val_loss: 0.8110 - val_accuracy: 0.7196\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - 310s 989ms/step - loss: 0.7912 - accuracy: 0.7246 - val_loss: 0.7556 - val_accuracy: 0.7371\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - 235s 752ms/step - loss: 0.7198 - accuracy: 0.7483 - val_loss: 0.7430 - val_accuracy: 0.7397\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 235s 751ms/step - loss: 0.6571 - accuracy: 0.7697 - val_loss: 0.7166 - val_accuracy: 0.7501\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 233s 744ms/step - loss: 0.5988 - accuracy: 0.7901 - val_loss: 0.6839 - val_accuracy: 0.7620\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 242s 774ms/step - loss: 0.5554 - accuracy: 0.8032 - val_loss: 0.7433 - val_accuracy: 0.7515\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 241s 771ms/step - loss: 0.5061 - accuracy: 0.8233 - val_loss: 0.6929 - val_accuracy: 0.7608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x217e3837c10>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310b60aa",
   "metadata": {},
   "source": [
    "### Testing out model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18450104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a377869a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5eca790e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.rint(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b73479e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "abe1d9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7109\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6e8e81",
   "metadata": {},
   "source": [
    "We get an accuracy of 71% on our test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59de5e25",
   "metadata": {},
   "source": [
    "## Dataset 3 - Imagenette (Resized to 160px) Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7be3a13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "from keras.layers import MaxPooling2D, InputLayer, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a85f660e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9469 images belonging to 10 classes.\n",
      "Found 3925 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "imagegen = ImageDataGenerator()\n",
    "# load train data\n",
    "train = imagegen.flow_from_directory(\"imagenette2-160/train/\", class_mode=\"categorical\", shuffle=False, batch_size=128, target_size=(224, 224))\n",
    "# load val data\n",
    "val = imagegen.flow_from_directory(\"imagenette2-160/val/\", class_mode=\"categorical\", shuffle=False, batch_size=128, target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1040a26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(224, 224, 3)))\n",
    "\n",
    "# 1st conv block\n",
    "model.add(Conv2D(25, (5, 5), activation='relu', strides=(1, 1), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "# 2nd conv block\n",
    "model.add(Conv2D(50, (5, 5), activation='relu', strides=(2, 2), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "# 3rd conv block\n",
    "model.add(Conv2D(70, (3, 3), activation='relu', strides=(2, 2), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='valid'))\n",
    "model.add(BatchNormalization())\n",
    "# ANN block\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "# output layer\n",
    "model.add(Dense(units=10, activation='softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71e13c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "821b2d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 224, 224, 25)      1900      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 112, 112, 25)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 56, 56, 50)        31300     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 28, 28, 50)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 28, 28, 50)       200       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 14, 14, 70)        31570     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 7, 7, 70)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 7, 7, 70)         280       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3430)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               343100    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 419,460\n",
      "Trainable params: 419,220\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd988d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "74/74 [==============================] - 390s 5s/step - loss: 2.2373 - accuracy: 0.2292 - val_loss: 2.9524 - val_accuracy: 0.1404\n",
      "Epoch 2/15\n",
      "74/74 [==============================] - 383s 5s/step - loss: 1.9107 - accuracy: 0.3538 - val_loss: 2.2234 - val_accuracy: 0.2385\n",
      "Epoch 3/15\n",
      "74/74 [==============================] - 323s 4s/step - loss: 1.7692 - accuracy: 0.4055 - val_loss: 2.2561 - val_accuracy: 0.2854\n",
      "Epoch 4/15\n",
      "74/74 [==============================] - 320s 4s/step - loss: 1.4871 - accuracy: 0.5007 - val_loss: 2.5133 - val_accuracy: 0.2550\n",
      "Epoch 5/15\n",
      "74/74 [==============================] - 293s 4s/step - loss: 1.4146 - accuracy: 0.5203 - val_loss: 3.1930 - val_accuracy: 0.2158\n",
      "Epoch 6/15\n",
      "74/74 [==============================] - 285s 4s/step - loss: 1.1167 - accuracy: 0.6245 - val_loss: 1.9902 - val_accuracy: 0.3804\n",
      "Epoch 7/15\n",
      "74/74 [==============================] - 275s 4s/step - loss: 0.9070 - accuracy: 0.6905 - val_loss: 1.8581 - val_accuracy: 0.4262\n",
      "Epoch 8/15\n",
      "74/74 [==============================] - 275s 4s/step - loss: 0.7538 - accuracy: 0.7472 - val_loss: 2.0597 - val_accuracy: 0.3766\n",
      "Epoch 9/15\n",
      "74/74 [==============================] - 289s 4s/step - loss: 0.6055 - accuracy: 0.7952 - val_loss: 2.3171 - val_accuracy: 0.3796\n",
      "Epoch 10/15\n",
      "74/74 [==============================] - 289s 4s/step - loss: 0.6240 - accuracy: 0.7941 - val_loss: 3.1449 - val_accuracy: 0.2925\n",
      "Epoch 11/15\n",
      "74/74 [==============================] - 316s 4s/step - loss: 0.4279 - accuracy: 0.8577 - val_loss: 2.2970 - val_accuracy: 0.4237\n",
      "Epoch 12/15\n",
      "74/74 [==============================] - 305s 4s/step - loss: 0.2729 - accuracy: 0.9163 - val_loss: 2.1048 - val_accuracy: 0.4290\n",
      "Epoch 13/15\n",
      "74/74 [==============================] - 301s 4s/step - loss: 0.2055 - accuracy: 0.9384 - val_loss: 2.2539 - val_accuracy: 0.4285\n",
      "Epoch 14/15\n",
      "74/74 [==============================] - 319s 4s/step - loss: 0.1788 - accuracy: 0.9465 - val_loss: 2.3700 - val_accuracy: 0.4349\n",
      "Epoch 15/15\n",
      "74/74 [==============================] - 378s 5s/step - loss: 0.1324 - accuracy: 0.9604 - val_loss: 2.3700 - val_accuracy: 0.4484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x143d6e9d850>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, epochs=15, validation_data=val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5b55b2",
   "metadata": {},
   "source": [
    "We managed to 96% training accuracy and 44% validation accuracy. The validation accuracy is bad but it is consistently improving with each epoch. Due to computing resource and time limitations I've stopped with 15 epochs but the model can be improved much more with more epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440eec1c",
   "metadata": {},
   "source": [
    "## Covid-19 X-ray Dataset (Own Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49213478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d53021d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 148 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    rescale=1/255, # Normalize the pixel values between 0 and 1\n",
    "    width_shift_range=0.10,\n",
    "    height_shift_range=0.10,\n",
    "    shear_range=0.1,\n",
    "    fill_mode='nearest',\n",
    "    rotation_range=20, \n",
    ")\n",
    "train_generator=train_datagen.flow_from_directory(\n",
    "    './xray_dataset_covid19/train',\n",
    "    class_mode='binary',\n",
    "    color_mode='rgb',\n",
    "    batch_size= 4,\n",
    "    target_size=(1000,1000,3)[:2]\n",
    ")\n",
    "\n",
    "test_datagen=ImageDataGenerator(rescale=1/255)\n",
    "test_generator=test_datagen.flow_from_directory(\n",
    "    './xray_dataset_covid19/test',\n",
    "    class_mode='binary',\n",
    "    color_mode='rgb',\n",
    "    batch_size=4,\n",
    "    target_size=(1000,1000,3)[:2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed0b302f",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop=EarlyStopping(patience=6)\n",
    "learning_rate_reduction=ReduceLROnPlateau(\n",
    "    monitor='val_acc',\n",
    "    patience= 3,\n",
    "    verbose=1,\n",
    "    factor=0.5,\n",
    "    min_lr=0.00001\n",
    ")\n",
    "callbacks = [earlystop, learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddaa3f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential() \n",
    "\n",
    "model.add(Conv2D(32,(2,2),activation='relu',input_shape=(1000,1000,3)))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Conv2D(64,(2,2),activation='relu'))\n",
    "model.add(MaxPooling2D(3,3))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(3,3))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam' ,loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04c25974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 999, 999, 32)      416       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 499, 499, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 498, 498, 64)      8256      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 166, 166, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 164, 164, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 186624)            0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 186624)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               23888000  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,933,729\n",
      "Trainable params: 23,933,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1524a743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n",
      "37/37 [==============================] - ETA: 0s - loss: 1.3780 - accuracy: 0.6216WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "37/37 [==============================] - 98s 3s/step - loss: 1.3780 - accuracy: 0.6216 - val_loss: 0.0897 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "Epoch 2/14\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.4531 - accuracy: 0.8446WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "37/37 [==============================] - 95s 3s/step - loss: 0.4531 - accuracy: 0.8446 - val_loss: 0.2109 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "Epoch 3/14\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.4963 - accuracy: 0.7838WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "37/37 [==============================] - 94s 3s/step - loss: 0.4963 - accuracy: 0.7838 - val_loss: 0.3133 - val_accuracy: 0.9000 - lr: 0.0010\n",
      "Epoch 4/14\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3997 - accuracy: 0.8446WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "37/37 [==============================] - 96s 3s/step - loss: 0.3997 - accuracy: 0.8446 - val_loss: 0.1226 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "Epoch 5/14\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3432 - accuracy: 0.8649WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "37/37 [==============================] - 95s 3s/step - loss: 0.3432 - accuracy: 0.8649 - val_loss: 0.1395 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "Epoch 6/14\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3406 - accuracy: 0.8514WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "37/37 [==============================] - 97s 3s/step - loss: 0.3406 - accuracy: 0.8514 - val_loss: 0.0502 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 7/14\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3203 - accuracy: 0.8716WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "37/37 [==============================] - 96s 3s/step - loss: 0.3203 - accuracy: 0.8716 - val_loss: 0.1114 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 8/14\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3102 - accuracy: 0.8716WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "37/37 [==============================] - 94s 3s/step - loss: 0.3102 - accuracy: 0.8716 - val_loss: 0.0594 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "Epoch 9/14\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2593 - accuracy: 0.8851WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "37/37 [==============================] - 94s 3s/step - loss: 0.2593 - accuracy: 0.8851 - val_loss: 0.0576 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "Epoch 10/14\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2116 - accuracy: 0.9122WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "37/37 [==============================] - 94s 3s/step - loss: 0.2116 - accuracy: 0.9122 - val_loss: 0.0498 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "Epoch 11/14\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.2321 - accuracy: 0.8919WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "37/37 [==============================] - 94s 3s/step - loss: 0.2321 - accuracy: 0.8919 - val_loss: 0.0588 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "Epoch 12/14\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1603 - accuracy: 0.9527WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "37/37 [==============================] - 94s 3s/step - loss: 0.1603 - accuracy: 0.9527 - val_loss: 0.0673 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "Epoch 13/14\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.1742 - accuracy: 0.9392WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "37/37 [==============================] - 95s 3s/step - loss: 0.1742 - accuracy: 0.9392 - val_loss: 0.0774 - val_accuracy: 0.9750 - lr: 0.0010\n",
      "Epoch 14/14\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.4121 - accuracy: 0.8716WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "37/37 [==============================] - 96s 3s/step - loss: 0.4121 - accuracy: 0.8716 - val_loss: 0.0499 - val_accuracy: 1.0000 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2667b0481c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_generator, \n",
    "    epochs=14,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a27b45",
   "metadata": {},
   "source": [
    "We managed to get a validation accuracy of 100% in the last epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da65f96",
   "metadata": {},
   "source": [
    "So there is no need of tuning any hyperparameters and hence I did not use hyperas for tuning (we've also already used hyperas in the previous lab experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84225cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
