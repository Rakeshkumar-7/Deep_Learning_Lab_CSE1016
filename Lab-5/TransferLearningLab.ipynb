{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAQDteNbocmI"
   },
   "source": [
    "1. **Transfer learning**\n",
    "> - finetuning\n",
    "> - feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SN3OanYMoqi1"
   },
   "source": [
    "<img src='https://pennylane.ai/qml/_images/transfer_learning_general.png' width=\"500\">\n",
    "\n",
    "*https://pennylane.ai/qml/demos/tutorial_quantum_transfer_learning.html*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCfzw7EyowD8"
   },
   "source": [
    "Transfer learning helps in utilising the information learnt by the network in one task/ application \n",
    "for a newer task/application\n",
    "> - helps in faster convergence\n",
    "    >- enables efficient learning with smaller datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0bLGesUYKNlS"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hIvOrfmA9IzP"
   },
   "outputs": [],
   "source": [
    "import gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ikpTGhnMKSlB",
    "outputId": "3028d96d-4af2-4010-c193-2f87e3f01d4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1gj0DqYGPbj8eU9Wfl_KEDJ79UTzaSp5M\n",
      "To: /content/rps_stop_phonemes_bdg.gz\n",
      "100% 41.4M/41.4M [00:00<00:00, 55.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "!gdown --fuzzy https://drive.google.com/file/d/1gj0DqYGPbj8eU9Wfl_KEDJ79UTzaSp5M/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VT9mqWQLLaWX"
   },
   "outputs": [],
   "source": [
    "!tar -xf rps_stop_phonemes_bdg.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "PjCantB5Qpdz"
   },
   "outputs": [],
   "source": [
    "!mv data/rjw0/powerspace/pytorch_CNN_RPS/data/clag_stop_bdg/  clag_stop_bdg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xRdEQj_bLhlc"
   },
   "outputs": [],
   "source": [
    "## resize with data generator\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nfP32he9Llx4",
    "outputId": "2c634416-5d97-4d62-eaf3-d7af56595dd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5816 images belonging to 3 classes.\n",
      "Found 615 images belonging to 3 classes.\n",
      "Found 312 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'clag_stop_bdg/train',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32\n",
    ")\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    'clag_stop_bdg/dev',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32\n",
    ")\n",
    "test_generator = val_datagen.flow_from_directory(\n",
    "    'clag_stop_bdg/test',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "0onlDHfLp8ca"
   },
   "outputs": [],
   "source": [
    "num_classes=train_generator.num_classes\n",
    "nb_train_samples = train_generator.samples\n",
    "nb_val_samples = validation_generator.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3mptL_xTL9tP",
    "outputId": "4c7afec0-97f5-41ba-ff66-bbafaaca185a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 1s 0us/step\n",
      "80150528/80134624 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model=tf.keras.applications.vgg19.VGG19(include_top=False, weights='imagenet', input_tensor=None, input_shape=(256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rtXpsuNdSuzo",
    "outputId": "f2859e85-dd16-4e2d-bda0-c501c01b98ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.pooling.MaxPooling2D at 0x7fd50cf7a210>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Uh7RJAtTxcI",
    "outputId": "8559a4a1-fdd0-44ec-eed0-6794d5b66ce4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 128, 128, 64) dtype=float32 (created by layer 'block1_pool')>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.layers[3].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eOsNWNZxUkTL",
    "outputId": "126d0418-532f-4bc8-dd87-4b7fbe0c607b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 32, 32, 256) dtype=float32 (created by layer 'block3_pool')>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.layers[11].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eq3zmYX5VLcX",
    "outputId": "d49baa6f-86b4-49c5-ec69-43646b556d8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 8, 8, 512) dtype=float32 (created by layer 'block5_pool')>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LZ2yS2YZTpVn"
   },
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bSVW7jKTBMqi"
   },
   "outputs": [],
   "source": [
    "def prepare_VGG_model_for_finetuning(freeze_baselayers=True):\n",
    "    \"\"\"\n",
    "    input_shape: When pretrained networks are utilised, the input shape for the network is generally \n",
    "    dependent on the shape of the data the pretrained networks were originally trained. It allows us the exact use of weights.++\n",
    "    \"\"\"\n",
    "    base_model=tf.keras.applications.vgg19.VGG19(include_top=False, weights='imagenet', input_tensor=None, input_shape=(256, 256, 3))    # freeze layers\n",
    "    if freeze_baselayers==True:\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable=False\n",
    "    # change here - take the output from different layers of the base model. Eg. base_model.output, base_model.layers[11].output\n",
    "    x =  base_model.output\n",
    "    # x = tf.keras.layers.GlobalAveragePooling2D(2)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dense(num_classes)(x)\n",
    "    prediction_layer = tf.keras.layers.Softmax()(x)\n",
    "\n",
    "    model_new = tf.keras.Model(inputs=base_model.input, outputs=prediction_layer)\n",
    "    return model_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "VCxYEi40xjbA"
   },
   "outputs": [],
   "source": [
    "model = prepare_VGG_model_for_finetuning(freeze_baselayers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hUCy4kJ3Ssq"
   },
   "source": [
    "Our problem is classifying the stop sounds that has limited examples for each class. We'd perform transfer learning from a better generic neural network model that is trained with much larger amounts of training data at various levels/layers of the model.\n",
    "\n",
    "| | side A (finetuning) | side B ( feature extraction ) |\n",
    "|---|---|---|\n",
    "|layer 1 |  |  | \n",
    "| layer2 | | |\n",
    "|layer 3 | |  |\n",
    "\n",
    "The learning rate and optimizers can be one of ( 0.01, 0.0001, 0.0003m, etc. ) and 'Adagrad', 'Adam', 'Adamax', 'Nadam', 'Optimizer', 'RMSprop', 'SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "UYaSPNzokSGu"
   },
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "optimizer_fn = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=optimizer_fn,\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oFK0HF9uux9z",
    "outputId": "7a855165-93be-42dc-ba4a-692ce3a574e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/181 [==============================] - 108s 516ms/step - loss: 1.1754 - accuracy: 0.3750 - val_loss: 1.1466 - val_accuracy: 0.4049\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator, steps_per_epoch=nb_train_samples//32, \n",
    "                   epochs=1, validation_data=validation_generator,\n",
    "                    validation_steps=nb_val_samples/32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLtkxBkWnxqG"
   },
   "source": [
    "Ref: \n",
    "- https://play.google.com/books/reader?id=mGSGDwAAQBAJ&hl=en&pg=GBS.PA43\n",
    "- https://keras.io/guides/transfer_learning/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
